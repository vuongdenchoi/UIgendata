import streamlit as st
import json
import os
import pandas as pd

# C·∫•u h√¨nh trang r·ªông
st.set_page_config(page_title="Medical QA Viewer", layout="wide")

# ƒê∆∞·ªùng d·∫´n v√† gi·ªõi h·∫°n
DATA_FOLDER = "examples/data_gen"
BATCH_SIZE = 100
SAVE_PATH = "merged_data_after_delete.json"

# --- Load danh s√°ch file .json trong th∆∞ m·ª•c ---
def list_json_files(folder):
    return sorted([f for f in os.listdir(folder) if f.endswith(".json")])

# --- Load batch d·ªØ li·ªáu t·ª´ file ---
def load_batch_json(file_list, start_index, batch_size):
    data = []
    end_index = min(start_index + batch_size, len(file_list))
    for filename in file_list[start_index:end_index]:
        try:
            with open(os.path.join(DATA_FOLDER, filename), "r", encoding="utf-8") as f:
                content = json.load(f)
                if isinstance(content, list):
                    for item in content:
                        data.append({
                            "filename": filename,
                            "Question": item.get("Question", ""),
                            "Complex_CoT": item.get("Complex_CoT", ""),
                            "Response": item.get("Response", ""),
                            "Question_translated": item.get("Question_translated", {}).get("result", ""),
                            "Complex_CoT_translated": item.get("Complex_CoT_translated", {}).get("result", ""),
                            "Response_translated": item.get("Response_translated", {}).get("result", ""),
                        })
                elif isinstance(content, dict):
                    data.append({
                        "filename": filename,
                        "Question": content.get("Question", ""),
                        "Complex_CoT": content.get("Complex_CoT", ""),
                        "Response": content.get("Response", ""),
                        "Question_translated": content.get("Question_translated", {}).get("result", ""),
                        "Complex_CoT_translated": content.get("Complex_CoT_translated", {}).get("result", ""),
                        "Response_translated": content.get("Response_translated", {}).get("result", ""),
                    })
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc file `{filename}`: {e}")
    return data

# --- L∆∞u JSON ---
def save_to_json(data_list, file_path):
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data_list, f, ensure_ascii=False, indent=2)

# --- KH·ªûI T·∫†O SESSION STATE ---
if "file_list" not in st.session_state:
    st.session_state.file_list = list_json_files(DATA_FOLDER)
    st.session_state.current_index = 0
    st.session_state.data = []

# --- LOAD D·ªÆ LI·ªÜU N·∫æU CH∆ØA C√ì ---
if not st.session_state.data:
    st.session_state.data = load_batch_json(
        st.session_state.file_list,
        st.session_state.current_index,
        BATCH_SIZE
    )

# --- T·∫†O DATAFRAME ---
df = pd.DataFrame(st.session_state.data)

# --- GIAO DI·ªÜN ---
st.title("üß† Medical QA Viewer - Ph√¢n trang t·ª´ng 100 file")
st.markdown(f"### T·ªïng s·ªë d√≤ng d·ªØ li·ªáu: {len(df)}")

columns = df.columns.tolist()

# --- HI·ªÇN TH·ªä HEADER ---
header_cols = st.columns(len(columns) + 1)
for i, col in enumerate(columns):
    header_cols[i].markdown(f"**{col}**")
header_cols[-1].markdown("**Xo√°**")

# --- HI·ªÇN TH·ªä D√íNG V√Ä N√öT XO√Å ---
for idx, row in df.iterrows():
    row_cols = st.columns(len(columns) + 1)
    for i, col in enumerate(columns):
        row_cols[i].markdown(
            f"<div style='word-wrap: break-word; white-space: pre-wrap;'>{str(row[col]).replace(chr(10), '<br>')}</div>",
            unsafe_allow_html=True
        )
    if row_cols[-1].button("üóëÔ∏è", key=f"delete_{idx}"):
        st.session_state.data.pop(idx)
        save_to_json(st.session_state.data, SAVE_PATH)
        st.success(f"‚úÖ ƒê√£ xo√° d√≤ng {idx+1} v√† l∆∞u v√†o `{SAVE_PATH}`")
        st.rerun()

# --- N√öT T·∫¢I FILE ---
st.markdown("---")
if os.path.exists(SAVE_PATH):
    with open(SAVE_PATH, "rb") as f:
        st.download_button("üì• T·∫£i d·ªØ li·ªáu ƒë√£ ch·ªânh s·ª≠a", f, file_name=SAVE_PATH, mime="application/json")

# --- N√öT LOAD TI·∫æP 100 FILE TI·∫æP THEO ---
next_index = st.session_state.current_index + BATCH_SIZE
if next_index < len(st.session_state.file_list):
    if st.button("‚û°Ô∏è Load th√™m 100 file ti·∫øp theo"):
        st.session_state.current_index = next_index
        st.session_state.data = load_batch_json(
            st.session_state.file_list,
            st.session_state.current_index,
            BATCH_SIZE
        )
        st.rerun()
else:
    st.info("‚úÖ ƒê√£ load to√†n b·ªô d·ªØ li·ªáu trong th∆∞ m·ª•c.")
